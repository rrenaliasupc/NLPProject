{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200b2780",
   "metadata": {},
   "source": [
    "# HomeAssistant BERT Training Data generation\n",
    "\n",
    "This notebook is used to generate data to train the BERT model for using sentences in Catalan.\n",
    "\n",
    "It is based in the existing intent definition in catalan in:\n",
    "https://github.com/home-assistant/intents/tree/main/sentences/ca\n",
    "\n",
    "Data from that repository is not to train a BERT system but for using it as a phrase structure to interpret the senteces to generate intents.\n",
    "\n",
    "In this notebook, we will expand those phrases to be able to use them to train a BERT system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec80b70",
   "metadata": {},
   "source": [
    "## Install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ce78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\rrena\\miniconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\rrena\\miniconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rrena\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rrena\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rrena\\miniconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rrena\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rrena\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30a0ad",
   "metadata": {},
   "source": [
    "## Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25768ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f75fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading expansion rules from .\\intents\\sentences\\ca\\_common.yaml\n",
      "assist_satellite_HassBroadcast.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\assist_satellite_HassBroadcast.yaml\n",
      "Loaded 6 sentences from assist_satellite_HassBroadcast.yaml\n",
      "climate_HassClimateGetTemperature.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\climate_HassClimateGetTemperature.yaml\n",
      "Loaded 248 sentences from climate_HassClimateGetTemperature.yaml\n",
      "climate_HassClimateSetTemperature.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\climate_HassClimateSetTemperature.yaml\n",
      "Loaded 1098 sentences from climate_HassClimateSetTemperature.yaml\n",
      "climate_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\climate_HassTurnOff.yaml\n",
      "Loaded 14618 sentences from climate_HassTurnOff.yaml\n",
      "climate_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\climate_HassTurnOn.yaml\n",
      "Loaded 30948 sentences from climate_HassTurnOn.yaml\n",
      "cover_HassGetState.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\cover_HassGetState.yaml\n",
      "Loaded 0 sentences from cover_HassGetState.yaml\n",
      "cover_HassSetPosition.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\cover_HassSetPosition.yaml\n",
      "Loaded 30422 sentences from cover_HassSetPosition.yaml\n",
      "cover_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\cover_HassTurnOff.yaml\n",
      "Loaded 2450 sentences from cover_HassTurnOff.yaml\n",
      "cover_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\cover_HassTurnOn.yaml\n",
      "Loaded 4410 sentences from cover_HassTurnOn.yaml\n",
      "fan_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\fan_HassTurnOff.yaml\n",
      "Loaded 2880 sentences from fan_HassTurnOff.yaml\n",
      "fan_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\fan_HassTurnOn.yaml\n",
      "Loaded 2160 sentences from fan_HassTurnOn.yaml\n",
      "homeassistant_HassCancelAllTimers.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassCancelAllTimers.yaml\n",
      "Loaded 1240 sentences from homeassistant_HassCancelAllTimers.yaml\n",
      "homeassistant_HassCancelTimer.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassCancelTimer.yaml\n",
      "Loaded 640 sentences from homeassistant_HassCancelTimer.yaml\n",
      "homeassistant_HassDecreaseTimer.yaml_DONOTUSE\n",
      "homeassistant_HassGetCurrentDate.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassGetCurrentDate.yaml\n",
      "Loaded 110 sentences from homeassistant_HassGetCurrentDate.yaml\n",
      "homeassistant_HassGetCurrentTime.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassGetCurrentTime.yaml\n",
      "Loaded 59 sentences from homeassistant_HassGetCurrentTime.yaml\n",
      "homeassistant_HassGetState.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassGetState.yaml\n",
      "Loaded 1056 sentences from homeassistant_HassGetState.yaml\n",
      "homeassistant_HassIncreaseTimer.yaml_DONOTUSE\n",
      "homeassistant_HassNevermind.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassNevermind.yaml\n",
      "Loaded 10 sentences from homeassistant_HassNevermind.yaml\n",
      "homeassistant_HassPauseTimer.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassPauseTimer.yaml\n",
      "Loaded 76 sentences from homeassistant_HassPauseTimer.yaml\n",
      "homeassistant_HassRespond.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassRespond.yaml\n",
      "Loaded 35 sentences from homeassistant_HassRespond.yaml\n",
      "homeassistant_HassStartTimer.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassStartTimer.yaml\n",
      "Warning: No expansion found for of. Keeping original.\n",
      "Warning: No expansion found for of. Keeping original.\n",
      "Warning: No expansion found for of. Keeping original.\n",
      "Warning: No expansion found for of. Keeping original.\n",
      "Loaded 1748 sentences from homeassistant_HassStartTimer.yaml\n",
      "homeassistant_HassTimerStatus.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassTimerStatus.yaml\n",
      "Warning: No expansion found for quant_queda. Keeping original.\n",
      "Warning: No expansion found for quant_queda. Keeping original.\n",
      "Warning: No expansion found for quant_queda. Keeping original.\n",
      "Warning: No expansion found for dades. Keeping original.\n",
      "Loaded 15 sentences from homeassistant_HassTimerStatus.yaml\n",
      "homeassistant_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassTurnOff.yaml\n",
      "Loaded 648 sentences from homeassistant_HassTurnOff.yaml\n",
      "homeassistant_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassTurnOn.yaml\n",
      "Loaded 1136 sentences from homeassistant_HassTurnOn.yaml\n",
      "homeassistant_HassUnpauseTimer.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\homeassistant_HassUnpauseTimer.yaml\n",
      "Warning: No expansion found for pronom_singular_temporitzador. Keeping original.\n",
      "Warning: No expansion found for pronom_singular_temporitzador. Keeping original.\n",
      "Warning: No expansion found for pronom_singular_temporitzador. Keeping original.\n",
      "Warning: No expansion found for pronom_singular_temporitzador. Keeping original.\n",
      "Warning: No expansion found for pronom_singular_temporitzador. Keeping original.\n",
      "Loaded 176 sentences from homeassistant_HassUnpauseTimer.yaml\n",
      "light_HassLightSet.yaml_DONOTUSE\n",
      "light_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\light_HassTurnOff.yaml\n",
      "Warning: No expansion found for everywhere. Keeping original.\n",
      "Warning: No expansion found for everywhere. Keeping original.\n",
      "Loaded 19972 sentences from light_HassTurnOff.yaml\n",
      "light_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\light_HassTurnOn.yaml\n",
      "Warning: No expansion found for everywhere. Keeping original.\n",
      "Warning: No expansion found for everywhere. Keeping original.\n",
      "Loaded 48823 sentences from light_HassTurnOn.yaml\n",
      "lock_HassTurnOff.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\lock_HassTurnOff.yaml\n",
      "Loaded 2640 sentences from lock_HassTurnOff.yaml\n",
      "lock_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\lock_HassTurnOn.yaml\n",
      "Loaded 784 sentences from lock_HassTurnOn.yaml\n",
      "media_player_HassMediaNext.yaml_DONOTUSE\n",
      "media_player_HassMediaPause.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\media_player_HassMediaPause.yaml\n",
      "Loaded 60 sentences from media_player_HassMediaPause.yaml\n",
      "media_player_HassMediaPrevious.yaml_DONOTUSE\n",
      "media_player_HassMediaUnpause.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\media_player_HassMediaUnpause.yaml\n",
      "Loaded 480 sentences from media_player_HassMediaUnpause.yaml\n",
      "media_player_HassSetVolume.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\media_player_HassSetVolume.yaml\n",
      "Loaded 11760 sentences from media_player_HassSetVolume.yaml\n",
      "person_HassGetState.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\person_HassGetState.yaml\n",
      "Warning: No expansion found for on. Keeping original.\n",
      "Warning: No expansion found for on. Keeping original.\n",
      "Warning: No expansion found for on. Keeping original.\n",
      "Warning: No expansion found for la_persona. Keeping original.\n",
      "Warning: No expansion found for la_persona. Keeping original.\n",
      "Warning: No expansion found for la_persona. Keeping original.\n",
      "Loaded 16 sentences from person_HassGetState.yaml\n",
      "scene_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\scene_HassTurnOn.yaml\n",
      "Loaded 496 sentences from scene_HassTurnOn.yaml\n",
      "script_HassTurnOn.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\script_HassTurnOn.yaml\n",
      "Loaded 48 sentences from script_HassTurnOn.yaml\n",
      "shopping_list_HassShoppingListAddItem.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\shopping_list_HassShoppingListAddItem.yaml\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Loaded 4 sentences from shopping_list_HassShoppingListAddItem.yaml\n",
      "todo_HassListAddItem.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\todo_HassListAddItem.yaml\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Warning: No expansion found for add. Keeping original.\n",
      "Loaded 20 sentences from todo_HassListAddItem.yaml\n",
      "vacuum_HassVacuumReturnToBase.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\vacuum_HassVacuumReturnToBase.yaml\n",
      "Loaded 48 sentences from vacuum_HassVacuumReturnToBase.yaml\n",
      "vacuum_HassVacuumStart.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\vacuum_HassVacuumStart.yaml\n",
      "Loaded 248 sentences from vacuum_HassVacuumStart.yaml\n",
      "valve_HassSetPosition.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\valve_HassSetPosition.yaml\n",
      "Loaded 156 sentences from valve_HassSetPosition.yaml\n",
      "weather_HassGetWeather.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\weather_HassGetWeather.yaml\n",
      "Warning: No expansion found for al_lloc. Keeping original.\n",
      "Warning: No expansion found for temps. Keeping original.\n",
      "Warning: No expansion found for temps. Keeping original.\n",
      "Warning: No expansion found for al_lloc. Keeping original.\n",
      "Loaded 20 sentences from weather_HassGetWeather.yaml\n",
      "_common.yaml\n",
      "Loading sentences from .\\intents\\sentences\\ca\\_common.yaml\n",
      "Loaded 0 sentences from _common.yaml\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'hass_intents_ca.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 230\u001b[0m\n\u001b[0;32m    228\u001b[0m data \u001b[38;5;241m=\u001b[39m process_directory(yaml_directory)\n\u001b[0;32m    229\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m--> 230\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset generat amb \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m frases i desat a: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rrena\\miniconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rrena\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rrena\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\rrena\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\rrena\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'hass_intents_ca.csv'"
     ]
    }
   ],
   "source": [
    "def load_expansion_rules(common_file_path):\n",
    "    \"\"\"\n",
    "    Load expansion rules from the _common.yaml file.\n",
    "    \"\"\"\n",
    "    print(f\"Loading expansion rules from {common_file_path}\")\n",
    "    with open(common_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = yaml.safe_load(f)\n",
    "    return content.get('expansion_rules', {})\n",
    "\n",
    "def expand_rules(sentence, expansion_rules):\n",
    "    \"\"\"\n",
    "    Expand rules in the sentence using the provided expansion rules.\n",
    "    \"\"\"\n",
    "    while '<' in sentence and '>' in sentence:\n",
    "        match = re.search(r'<(.*?)>', sentence)\n",
    "        if not match:\n",
    "            break\n",
    "        rule_name = match.group(1)\n",
    "        rule_expansion = expansion_rules.get(rule_name, f\"<{rule_name}>\")\n",
    "        #print(f\"Expanding rule: {rule_name} -> {rule_expansion}\")\n",
    "        old_sentence = sentence\n",
    "        sentence = sentence.replace(f\"<{rule_name}>\", rule_expansion, 1)\n",
    "        if sentence == old_sentence:\n",
    "            print(f\"Warning: No expansion found for {rule_name}. Keeping original.\")\n",
    "            break\n",
    "    return sentence\n",
    "\n",
    "def expand_sentence(sentence, expansion_rules):\n",
    "    sentences = [sentence]\n",
    "    outsentences=[]\n",
    "    for sentence in sentences:\n",
    "        outsentences.append(expand_rules(sentence, expansion_rules))\n",
    "\n",
    "    sentences = outsentences\n",
    "    outsentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence_outsentences = expand_sentence_blocks(sentence)\n",
    "        for sentence_outsentence in sentence_outsentences:\n",
    "            outsentences.append(sentence_outsentence)\n",
    "\n",
    "    sentences = outsentences\n",
    "    return sentences\n",
    "\n",
    "def expand_sentence_blocks(sentence):\n",
    "    sentences= [sentence]\n",
    "    expanded=True\n",
    "    while expanded:\n",
    "        #print(\"sentences:\",sentences)        \n",
    "        expanded=False\n",
    "        outsentences = []\n",
    "        for sentence in sentences:\n",
    "            expanded_sentences,expanded_inner=expand_blocks(sentence)\n",
    "            if expanded_inner:\n",
    "                expanded=True\n",
    "            for expanded_sentence in expanded_sentences:\n",
    "                outsentences.append(expanded_sentence)\n",
    "            #print(\"outsentences:\",outsentences)\n",
    "        #remove duplicates\n",
    "        for i in range(len(outsentences)):\n",
    "            for j in range(i+1, len(outsentences)):\n",
    "                if outsentences[i] == outsentences[j]:\n",
    "                    outsentences.pop(j)\n",
    "                    break\n",
    "        \n",
    "        sentences = outsentences\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def expand_sentence_x(sentence, expansion_rules):\n",
    "    \"\"\"\n",
    "    Expand phrases between [], (), and <> and maintain entities {name}.\n",
    "    Handles nested expandable blocks in a single sentence.\n",
    "    \"\"\"\n",
    "    # Primer, expandim els blocs entre parèntesis com un nivell superior\n",
    "    if '(' in sentence and ')' in sentence:\n",
    "        parts = re.split(r'(\\(.*?\\))', sentence)\n",
    "        expanded_sentences = []\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.startswith('(') and part.endswith(')'):\n",
    "                options = part[1:-1].split('|')\n",
    "                if not expanded_sentences:\n",
    "                    expanded_sentences = options\n",
    "                else:\n",
    "                    expanded_sentences = [\n",
    "                        f\"{prev}{opt}\" for prev in expanded_sentences for opt in options\n",
    "                    ]\n",
    "            else:\n",
    "                if not expanded_sentences:\n",
    "                    expanded_sentences = [part]\n",
    "                else:\n",
    "                    expanded_sentences = [f\"{prev}{part}\" for prev in expanded_sentences]\n",
    "    else:\n",
    "        expanded_sentences = [sentence]\n",
    "\n",
    "    # Ara, expandim els blocs entre claudàtors dins de cada frase generada\n",
    "    final_sentences = []\n",
    "    for expanded in expanded_sentences:\n",
    "        parts = re.split(r'(\\[.*?\\])', expanded)\n",
    "        tokens = []\n",
    "\n",
    "        for part in parts:\n",
    "            if part.startswith('[') and part.endswith(']'):\n",
    "                options = part[1:-1].split('|')\n",
    "                tokens.append(options)\n",
    "            else:\n",
    "                tokens.append([part])\n",
    "\n",
    "        combinations = list(itertools.product(*tokens))\n",
    "        final_sentences.extend([''.join(combo).strip() for combo in combinations])\n",
    "\n",
    "    #return final_sentences\n",
    "\n",
    "    # Finalment, expandim els blocs entre <rule> utilitzant les expansion_rules\n",
    "    fully_expanded_sentences = []\n",
    "    for sentence in final_sentences:\n",
    "        while '<' in sentence and '>' in sentence:\n",
    "            match = re.search(r'<(.*?)>', sentence)\n",
    "            if not match:\n",
    "                break\n",
    "            rule_name = match.group(1)\n",
    "            rule_expansion = expansion_rules.get(rule_name, f\"<{rule_name}>\")\n",
    "            print(f\"Expanding rule: {rule_name} -> {rule_expansion}\")\n",
    "            old_sentence = sentence\n",
    "            sentence = sentence.replace(f\"<{rule_name}>\", rule_expansion, 1)\n",
    "            if sentence == old_sentence:\n",
    "                print(f\"Warning: No expansion found for {rule_name}. Keeping original.\")\n",
    "                break\n",
    "        fully_expanded_sentences.append(sentence)\n",
    "\n",
    "    return fully_expanded_sentences\n",
    "\n",
    "def load_sentences_from_yaml(file_path, expansion_rules):\n",
    "    print(f\"Loading sentences from {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = yaml.safe_load(f)\n",
    "\n",
    "    data = []\n",
    "    # Navigate through the YAML structure\n",
    "    for intent_name, intent_data in content.get('intents', {}).items():\n",
    "        for item in intent_data.get('data', []):\n",
    "            sentences = item.get('sentences', [])\n",
    "            for sentence in sentences:\n",
    "                expanded = expand_sentence(sentence,expansion_rules)\n",
    "                for s in expanded:\n",
    "                    data.append({'sentence': s, 'intent': intent_name})\n",
    "    return data\n",
    "\n",
    "def process_directory(yaml_dir):\n",
    "    all_data = []\n",
    "    # Process general YAML files\n",
    "    common_file_path = os.path.join(yaml_dir, \"_common.yaml\")\n",
    "    expansion_rules = load_expansion_rules(common_file_path)\n",
    "\n",
    "    # Process each YAML file in the directory\n",
    "    for file_name in os.listdir(yaml_dir):\n",
    "        print(file_name)\n",
    "        if file_name.endswith('.yaml') or file_name.endswith('.yml'):\n",
    "            path = os.path.join(yaml_dir, file_name)\n",
    "            sentences=load_sentences_from_yaml(path,expansion_rules)\n",
    "            all_data.extend(sentences)\n",
    "            print(f\"Loaded {len(sentences)} sentences from {file_name}\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def expand_blocks(sentence):\n",
    "    \"\"\"\n",
    "    Expand blocks in the sentence between the specified initial and end characters.\n",
    "    \"\"\"\n",
    "    initial_chars = ['(','[']\n",
    "    end_chars = [')',']']\n",
    "    #print(sentence)\n",
    "    expanded_sentences = []\n",
    "    expanded=False\n",
    "    #if sentence contains any of the initial characters and end characters\n",
    "    if any(char in sentence for char in initial_chars) and any(char in sentence for char in end_chars):\n",
    "        end_char_pos_found= False\n",
    "        initial_char_pos2_found = False\n",
    "        for initial_char_pos in range(len(sentence)):\n",
    "            if sentence[initial_char_pos] in initial_chars:\n",
    "                break;\n",
    "        for end_char_pos in range(initial_char_pos+1, len(sentence)):\n",
    "            if sentence[end_char_pos] in end_chars:\n",
    "                end_char_pos_found = True\n",
    "                break;\n",
    "\n",
    "        for initial_char_pos2 in range(initial_char_pos+1, len(sentence)):\n",
    "            if sentence[initial_char_pos2] in initial_chars:\n",
    "                initial_char_pos2_found = True\n",
    "                break;\n",
    "        \n",
    "        #print(\"initial_char_pos:\",initial_char_pos)\n",
    "        #print(\"end_char_pos:\",end_char_pos)\n",
    "        #print(\"initial_char_pos2:\",initial_char_pos2)\n",
    "\n",
    "        if end_char_pos_found and initial_char_pos2_found and initial_char_pos2 < end_char_pos:\n",
    "            #execute the expansion recursive between the initial2 and end characters                       \n",
    "            generatedsubstrings,expanded = expand_blocks(sentence[initial_char_pos2:end_char_pos+1])\n",
    "            #print(\"generatedsubstrings:\",generatedsubstrings)\n",
    "            for generatedsubstring in generatedsubstrings:\n",
    "                #print(\"generatedsubstring:\",generatedsubstring)\n",
    "                expanded_sentences.append(sentence[:initial_char_pos2] + generatedsubstring + sentence[end_char_pos+1:])\n",
    "        else:\n",
    "            #expand the sentence between the initial and end characters generate as may sentences as values separeted by |\n",
    "            \n",
    "            options = sentence[initial_char_pos+1:end_char_pos].split('|')\n",
    "            #print(\"options:\",options)\n",
    "            for option in options:\n",
    "                #print(\"option:\",option)\n",
    "                expanded_sentences.append(sentence[:initial_char_pos] + option + sentence[end_char_pos+1:])\n",
    "                expanded=True\n",
    "\n",
    "            #print(\"expanded_sentences1:\",expanded_sentences)\n",
    "        \n",
    "    else:\n",
    "        expanded_sentences = [sentence]\n",
    "    #print(\"expanded_sentences2:\",expanded_sentences)\n",
    "    #print(\"expanded:\",expanded)\n",
    "    \n",
    "    return expanded_sentences, expanded\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    yaml_directory = r\".\\intents\\sentences\\ca\"\n",
    "    #yaml_directory = r\".\\test_ca\"\n",
    "    output_csv = \"hass_intents_ca.csv\"\n",
    "\n",
    "    data = process_directory(yaml_directory)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dataset generat amb {len(df)} frases i desat a: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
